{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어를 분류하기 위해 기초적인 문자-단위 RNN을 구축하고 학습 할 예정입니다.\n",
    "이 튜토리얼에서는 (이후 2개 튜토리얼과 함께) NLP 모델링을 위한 데이터 전처리를\n",
    "`torchtext` 의 편리한 많은 기능들을 사용하지 않고 어떻게 하는지 \"기초부터(from scratch)\"\n",
    "보여주기 떄문에  NLP 모델링을 위한 전처리가 저수준에서 어떻게 진행되는지를 알 수 있습니다.\n",
    "문자-단위 RNN은 단어를 문자의 연속으로 읽어 들여서 각 단계의 예측과\n",
    "\"은닉 상태(Hidden State)\" 출력하고, 다음 단계에 이전 은닉 상태를 전달합니다.\n",
    "단어가 속한 클래스로 출력이 되도록 최종 예측으로 선택합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입력 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 문자를 표현하기 위해, 크기가 ``<1 x n_letters>`` 인\n",
    "\"One-Hot 벡터\" 를 사용합니다. One-Hot 벡터는 현재 문자의\n",
    "주소에만 1을 값으로 가지고 그외에 나머지는 0으로 채워집니다.  \n",
    "예시 ``\"b\" = <0 1 0 0 0 ...>`` .\n",
    "\n",
    "단어를 만들기 위해 One-Hot 벡터들을 2 차원 행렬\n",
    "``<line_length x 1 x n_letters>`` 에 결합시킵니다.\n",
    "\n",
    "위에서 보이는 추가적인 1차원은 PyTorch에서 모든 것이 배치(batch)에 있다고 가정하기\n",
    "때문에 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# singleton example\n",
    "# shape : (1, 1, 4)\n",
    "# input_data_np = np.array([[[1, 0, 0, 0]]])\n",
    "\n",
    "# sequential example\n",
    "# shape : (3, 5, 4)\n",
    "h = [1., 0., 0., 0.]\n",
    "e = [0., 1., 0., 0.]\n",
    "l = [0., 0., 1., 0.]\n",
    "o = [0., 0., 0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor([[h, e, l, l, o], [e, o, l, l, l], [l, l, e, e, l]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd 전에, Torch에서 RNN(recurrent neural network) 생성은\n",
    "여러 시간 단계 걸처서 계층의 매개변수를 복제하는 작업을 포함합니다.\n",
    "계층은 은닉 상태와 변화도(Gradient)를 가지며, 이제 이것들은 그래프 자체에서\n",
    "완전히 처리됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ref : https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn_caluclate](../_static/rnn_calculate.png)\n",
    "\n",
    "(ref: https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 선언\n",
    "rnn = torch.nn.RNN(input_size=4, hidden_size=2, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(4, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 객체가 보유하고 있는 모든 attribute 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nonlinearity': 'tanh',\n",
       " 'training': True,\n",
       " '_parameters': OrderedDict([('weight_ih_l0',\n",
       "               Parameter containing:\n",
       "               tensor([[-0.0053,  0.3793, -0.5820, -0.5204],\n",
       "                       [-0.2723,  0.1896, -0.0140,  0.5607]], requires_grad=True)),\n",
       "              ('weight_hh_l0',\n",
       "               Parameter containing:\n",
       "               tensor([[-0.0628,  0.1871],\n",
       "                       [-0.2137, -0.1390]], requires_grad=True)),\n",
       "              ('bias_ih_l0',\n",
       "               Parameter containing:\n",
       "               tensor([-0.6755, -0.4683], requires_grad=True)),\n",
       "              ('bias_hh_l0',\n",
       "               Parameter containing:\n",
       "               tensor([-0.2915,  0.0262], requires_grad=True))]),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'mode': 'RNN_TANH',\n",
       " 'input_size': 4,\n",
       " 'hidden_size': 2,\n",
       " 'num_layers': 1,\n",
       " 'bias': True,\n",
       " 'batch_first': False,\n",
       " 'dropout': 0.0,\n",
       " 'bidirectional': False,\n",
       " 'proj_size': 0,\n",
       " '_flat_weights_names': ['weight_ih_l0',\n",
       "  'weight_hh_l0',\n",
       "  'bias_ih_l0',\n",
       "  'bias_hh_l0'],\n",
       " '_all_weights': [['weight_ih_l0',\n",
       "   'weight_hh_l0',\n",
       "   'bias_ih_l0',\n",
       "   'bias_hh_l0']],\n",
       " '_flat_weights': [Parameter containing:\n",
       "  tensor([[-0.0053,  0.3793, -0.5820, -0.5204],\n",
       "          [-0.2723,  0.1896, -0.0140,  0.5607]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0628,  0.1871],\n",
       "          [-0.2137, -0.1390]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.6755, -0.4683], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.2915,  0.0262], requires_grad=True)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0053,  0.3793, -0.5820, -0.5204], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.2723,  0.1896, -0.0140,  0.5607], grad_fn=<UnbindBackward>)\n"
     ]
    }
   ],
   "source": [
    "for param in iter(next(rnn.parameters())):\n",
    "    print(param)  # RNN의 파라미터만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layers RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층 RNN 선언 (num_layers 로 레이어의 개수 설정 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_multi_layers = torch.nn.RNN(input_size=4, hidden_size=2, num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(4, 2, num_layers=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_multi_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0',\n",
       "              Parameter containing:\n",
       "              tensor([[ 0.2795,  0.4243, -0.4794, -0.3079],\n",
       "                      [ 0.2568,  0.5872, -0.1455,  0.5291]], requires_grad=True)),\n",
       "             ('weight_hh_l0',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.1140,  0.0748],\n",
       "                      [ 0.6403, -0.6560]], requires_grad=True)),\n",
       "             ('bias_ih_l0',\n",
       "              Parameter containing:\n",
       "              tensor([-0.4452, -0.1790], requires_grad=True)),\n",
       "             ('bias_hh_l0',\n",
       "              Parameter containing:\n",
       "              tensor([-0.2756,  0.6109], requires_grad=True)),\n",
       "             ('weight_ih_l1',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.4583, -0.3255],\n",
       "                      [-0.4940, -0.6622]], requires_grad=True)),\n",
       "             ('weight_hh_l1',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.4128,  0.6078],\n",
       "                      [ 0.3155,  0.3427]], requires_grad=True)),\n",
       "             ('bias_ih_l1',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.0372, -0.3625], requires_grad=True)),\n",
       "             ('bias_hh_l1',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.1196, -0.6602], requires_grad=True)),\n",
       "             ('weight_ih_l2',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.5109, -0.3645],\n",
       "                      [ 0.4461,  0.4146]], requires_grad=True)),\n",
       "             ('weight_hh_l2',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.3136, -0.0255],\n",
       "                      [ 0.4522,  0.7030]], requires_grad=True)),\n",
       "             ('bias_ih_l2',\n",
       "              Parameter containing:\n",
       "              tensor([0.2806, 0.0955], requires_grad=True)),\n",
       "             ('bias_hh_l2',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.4741, -0.4163], requires_grad=True))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_multi_layers._parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입출력 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터에 대한 RNN의 output 및 히든 레이어의 아웃풋 (hidden state) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, hidden_state = rnn(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7497, -0.6135],\n",
      "         [-0.5282, -0.2473],\n",
      "         [-0.9136, -0.4269],\n",
      "         [-0.9136, -0.4269],\n",
      "         [-0.9028,  0.1180]],\n",
      "\n",
      "        [[-0.5753, -0.0070],\n",
      "         [-0.9052,  0.2597],\n",
      "         [-0.9173, -0.1989],\n",
      "         [-0.9173, -0.1989],\n",
      "         [-0.8996, -0.2725]],\n",
      "\n",
      "        [[-0.9077, -0.3205],\n",
      "         [-0.8944, -0.2902],\n",
      "         [-0.5134, -0.0288],\n",
      "         [-0.5134, -0.0288],\n",
      "         [-0.9127, -0.2222]]], grad_fn=<StackBackward>)\n",
      "torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9077, -0.3205],\n",
      "         [-0.8944, -0.2902],\n",
      "         [-0.5134, -0.0288],\n",
      "         [-0.5134, -0.0288],\n",
      "         [-0.9127, -0.2222]]], grad_fn=<StackBackward>)\n",
      "torch.Size([1, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(hidden_state)\n",
    "print(hidden_state.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터에 대한 다층 RNN의 output 및 히든 레이어의 아웃풋 (hidden state) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, hidden_state = rnn_multi_layers(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7543, -0.5375],\n",
      "         [ 0.7845, -0.5849],\n",
      "         [ 0.6533, -0.3864],\n",
      "         [ 0.6533, -0.3864],\n",
      "         [ 0.7243, -0.4933]],\n",
      "\n",
      "        [[ 0.7869, -0.7195],\n",
      "         [ 0.7127, -0.6512],\n",
      "         [ 0.5887, -0.4131],\n",
      "         [ 0.5887, -0.4131],\n",
      "         [ 0.5597, -0.4298]],\n",
      "\n",
      "        [[ 0.6109, -0.6075],\n",
      "         [ 0.5860, -0.5538],\n",
      "         [ 0.7732, -0.6762],\n",
      "         [ 0.7732, -0.6762],\n",
      "         [ 0.6341, -0.5182]]], grad_fn=<StackBackward>)\n",
      "torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8182, -0.0702],\n",
      "         [-0.7993, -0.3433],\n",
      "         [-0.2320,  0.6506],\n",
      "         [-0.2320,  0.6506],\n",
      "         [-0.8197,  0.1777]],\n",
      "\n",
      "        [[ 0.1845, -0.7633],\n",
      "         [ 0.1997, -0.6192],\n",
      "         [-0.2353, -0.8978],\n",
      "         [-0.2353, -0.8978],\n",
      "         [ 0.1801, -0.6859]],\n",
      "\n",
      "        [[ 0.6109, -0.6075],\n",
      "         [ 0.5860, -0.5538],\n",
      "         [ 0.7732, -0.6762],\n",
      "         [ 0.7732, -0.6762],\n",
      "         [ 0.6341, -0.5182]]], grad_fn=<StackBackward>)\n",
      "torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(hidden_state)\n",
    "print(hidden_state.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. RNN 모듈을 LSTM 으로 변경하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM 모듈에 대한 ref\n",
    "\n",
    "(ref : https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 선언\n",
    "lstm = torch.nn.??(input_size=4, hidden_size=2, num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(4, 2, num_layers=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, (hidden_state, _) = lstm(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0684,  0.1712],\n",
      "         [-0.0680,  0.1788],\n",
      "         [-0.0682,  0.1728],\n",
      "         [-0.0682,  0.1728],\n",
      "         [-0.0681,  0.1772]],\n",
      "\n",
      "        [[-0.0879,  0.2323],\n",
      "         [-0.0883,  0.2345],\n",
      "         [-0.0879,  0.2272],\n",
      "         [-0.0879,  0.2272],\n",
      "         [-0.0881,  0.2290]],\n",
      "\n",
      "        [[-0.0939,  0.2460],\n",
      "         [-0.0941,  0.2466],\n",
      "         [-0.0936,  0.2497],\n",
      "         [-0.0936,  0.2497],\n",
      "         [-0.0937,  0.2444]]], grad_fn=<StackBackward>)\n",
      "torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# output 호출\n",
    "print(outputs)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0567,  0.0531],\n",
      "         [ 0.0675,  0.0558],\n",
      "         [ 0.0672, -0.1853],\n",
      "         [ 0.0672, -0.1853],\n",
      "         [ 0.0715,  0.0583]],\n",
      "\n",
      "        [[ 0.0833, -0.1614],\n",
      "         [ 0.0842, -0.1605],\n",
      "         [ 0.0980, -0.1692],\n",
      "         [ 0.0980, -0.1692],\n",
      "         [ 0.0774, -0.1625]],\n",
      "\n",
      "        [[-0.0939,  0.2460],\n",
      "         [-0.0941,  0.2466],\n",
      "         [-0.0936,  0.2497],\n",
      "         [-0.0936,  0.2497],\n",
      "         [-0.0937,  0.2444]]], grad_fn=<StackBackward>)\n",
      "torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(hidden_state)\n",
    "print(hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(ref: https://github.com/deeplearningzerotoall/PyTorch)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
