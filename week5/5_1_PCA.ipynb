{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e58314",
   "metadata": {},
   "source": [
    "# Principal component analysis (PCA)\n",
    "- PCA는 feature 공간에서 최대 분산을 가지는 직교 방향을 찾는것이 목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                      'machine-learning-databases/wine/wine.data',\n",
    "                      header=None)\n",
    "\n",
    "# if the Wine dataset is temporarily unavailable from the\n",
    "# UCI machine learning repository, un-comment the following line\n",
    "# of code to load the dataset from a local path:\n",
    "\n",
    "# df_wine = pd.read_csv('wine.data', header=None)\n",
    "\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue',\n",
    "                   'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a89e438",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "- 학습 / 테스트 데이터셋으로 분리\n",
    "- 데이터 standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a62c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, \n",
    "                     stratify=y,\n",
    "                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a10dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d536d",
   "metadata": {},
   "source": [
    "## 공분산행렬(covariance matrix) 에 대한 eigen-decomposition\n",
    "- 행렬 $A$에 대한 eigen-decomposition은 다음과 같이 계산됨  \n",
    "$$\n",
    "    A=Q\\Lambda Q^T\n",
    "$$\n",
    "\n",
    "- $Q$는 열(column)로서 $A$의 고유벡터(eigen vector)에 대한 orthonomal matrix \n",
    "- $\\Lambda$ 는 고유값들(eigenvalues)로 이루어진 대각행렬(diagonal matrix)\n",
    "- $A$는 모든 고유값이 실수가 되도록 대칭이어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99be34d",
   "metadata": {},
   "source": [
    "$$\n",
    "z := \\begin{bmatrix} z^{(1)} \\\\ \\vdots \\\\ z^{(n)} \\end{bmatrix}= Xv \\in \n",
    "\\mathbb{R}^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dfade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cov_mat = np.cov(X_train_std.T)\n",
    "\n",
    "print('Dim of X_train_std', np.shape(X_train_std))\n",
    "print('Dim of cov matrix', np.shape(cov_mat))\n",
    "\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('\\nEigenvalues \\n', eigen_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd02175",
   "metadata": {},
   "source": [
    "## Total and explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d64aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0bc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535470f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.bar(range(1, 14), var_exp, align='center',\n",
    "        label='Individual explained variance')\n",
    "plt.step(range(1, 14), cum_var_exp, where='mid',\n",
    "         label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/05_02.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538a84b",
   "metadata": {},
   "source": [
    "## Feature transformation (Projection onto PCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9672c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])\n",
    "               for i in range(len(eigen_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse=True)\n",
    "\n",
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "               eigen_pairs[1][1][:, np.newaxis]))\n",
    "print('Matrix W:\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca62e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eigen_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95870ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_std[0], X_train_std[0].dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04193c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_pca = X_train_std.dot(w)\n",
    "colors = ['r', 'b', 'g']\n",
    "markers = ['o', 's', '^']\n",
    "\n",
    "for l, c, m in zip(np.unique(y_train), colors, markers):\n",
    "    plt.scatter(X_train_pca[y_train == l, 0], \n",
    "                X_train_pca[y_train == l, 1], \n",
    "                c=c, label=f'Class {l}', marker=m)\n",
    "\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/05_03.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1fd37",
   "metadata": {},
   "source": [
    "## scikit learn 라이브러리를 통한 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46671c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b72eba",
   "metadata": {},
   "source": [
    "- scikit learn 라이브러리를 활용한 PCA 에서도 동일하게 explained variance ratio가 형성됨을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091fddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(1, 14), pca.explained_variance_ratio_, align='center')\n",
    "plt.step(range(1, 14), np.cumsum(pca.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6df875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1])\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('o', 's', '^', 'v', '<')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    lab = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    lab = lab.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class examples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=f'Class {cl}', \n",
    "                    edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d4c6b",
   "metadata": {},
   "source": [
    "### Training logistic regression classifier using the first 2 principal components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf35704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "lr = LogisticRegression(multi_class='ovr', random_state=1, solver='lbfgs')\n",
    "lr = lr.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07eebc",
   "metadata": {},
   "source": [
    "- trainset plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6468a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train_pca, y_train, classifier=lr)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/05_04.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f31198",
   "metadata": {},
   "source": [
    "- testset plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d35f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test_pca, y_test, classifier=lr)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/05_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e64d7",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0000854a",
   "metadata": {},
   "source": [
    "### 문제 1. \n",
    "- PCA를 활용해 아래에 주어진 toy 데이터셋을 5 principal components로 이루어진 feature 공간으로 변형하시오. (Hint: 데이터 정규화(standardization) 필요)\n",
    "- 아래 plot의 경우 단순히 데이터 X의 0번째 feature와 1번째 feature를 plotting 한것이므로 feature transformation이 일어난것이 아님!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "# Toy example 생성\n",
    "X, y = make_blobs(n_samples=200, n_features=20, centers=5, random_state=777)\n",
    "# X, y = make_blobs(n_samples=100, n_features=2, centers=2, cluster_std=1.0)\n",
    "\n",
    "# Plot the generated dataset\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Toy Example Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d165f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0418f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1-1. X, y train / text split 진행 (train_test_split 함수 사용)\n",
    "\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "\n",
    "# 문제 1-2. 데이터셋 정규화 (StandardScaler 를 활용해서 정규화 진행)\n",
    "\n",
    "X_train_std = ...\n",
    "X_test_std = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1-3. scikit learn 라이브러리의 PCA를 활용하여 feature transformation 진행\n",
    "\n",
    "pca = ...\n",
    "\n",
    "X_train_pca = ...\n",
    "X_test_pca = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1-4. 지난 수업시간에 배운 RandomForestClassifier를 활용해 해당 데이터셋을 분류하는 분류기 모델 학습\n",
    "\n",
    "rf_clf = ... # 모델 선언\n",
    "# 모델 학습\n",
    "...\n",
    "\n",
    "# 학습한 모델 성능 평가\n",
    "...\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c46d99",
   "metadata": {},
   "source": [
    "## 문제 2.\n",
    "\n",
    "- 아래 주어진 데이터셋 (breast cancer wisconsin dataset) 을 PCA를 활용해 데이터 차원축소를 진행하고, (5 이하) 랜덤포레스트 분류기 모델을 학습하고 성능평가를 진행하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d344ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a7567",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bf6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 풀이 진행\n",
    "...\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
